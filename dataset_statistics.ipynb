{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab. \")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    os.chdir('/content/gdrive/MyDrive/Tesi/dataset')\n",
    "else:\n",
    "    os.chdir('./dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading, Reading and Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_directories(orig_path, dest_path):\n",
    "    # Check if the destination folder exists, otherwise create it\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.makedirs(dest_path)\n",
    "    \n",
    "    # Iter over all files and folders in the source directory\n",
    "    for item in os.listdir(orig_path):\n",
    "        orig_item_path = os.path.join(orig_path, item)\n",
    "        \n",
    "        # Check if it is a folder\n",
    "        if os.path.isdir(orig_item_path):\n",
    "            # Defines the destination path for the folder\n",
    "            dest_item_path = os.path.join(dest_path, item)\n",
    "            \n",
    "            # Move the folder by renaming it\n",
    "            os.rename(orig_item_path, dest_item_path)\n",
    "            print(f\"Moved directory: {orig_item_path} -> {dest_item_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Check if some subdirectories are not empty\n",
    "path_to_check = \"./LUFlow/\"\n",
    "subdirs = [d for d in os.listdir(path_to_check) if os.path.isdir(os.path.join(path_to_check, d))]\n",
    "non_empty_subdirs = [d for d in subdirs if os.listdir(os.path.join(path_to_check, d))]\n",
    "\n",
    "dest_path = './LUFlow'\n",
    "\n",
    "if non_empty_subdirs:\n",
    "    print(\"Non-empty subdirectories:\", non_empty_subdirs)\n",
    "    print(\"Skip downloading.\")\n",
    "else:\n",
    "    print(\"All subdirectories are empty.\")\n",
    "    print(\"Download dataset.\")\n",
    "\n",
    "    # Download latest version\n",
    "    path = kagglehub.dataset_download(\"mryanm/luflow-network-intrusion-detection-data-set\")\n",
    "\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    move_directories(path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset = '2021.02'\n",
    "\n",
    "df_list = []\n",
    "i=0\n",
    "\n",
    "for root, dirs, files in os.walk(dest_path):\n",
    "    for file in files:\n",
    "        # checks if 'file' does not exist in the directory\n",
    "        # checks if 'csv' is in the file name\n",
    "        # checks if a particular string is in the file name\n",
    "        # insert in the list only a subset of the existing files\n",
    "        if not os.path.isfile(file) and 'csv' in file: #and subset in file and i < 5:\n",
    "            chunk_iter = pd.read_csv(os.path.join(root, file), chunksize=10000)\n",
    "            for chunk in chunk_iter:\n",
    "                df_list.append(chunk)\n",
    "            \n",
    "            del chunk_iter\n",
    "            gc.collect()\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "del df_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For selected colums see central tendency (mean and variance)\n",
    "- Benign, malicious percentage\n",
    "- Analize trends of benign, malicious for the three different years\n",
    "- See quantity of missing data is relevant\n",
    "- Correlation matrix (codice stava già fatto nel codice iniziale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes distribution (Benign and Malicious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = df['label'].value_counts(normalize=True) * 100\n",
    "print(perc)\n",
    "\n",
    "perc.plot(kind='pie', autopct='%1.1f%%', startangle=90, cmap='viridis')\n",
    "plt.title(\"Percentage distribution of classes\")\n",
    "plt.ylabel(\"\")  # Per nascondere l'etichetta dell'asse y\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns values distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non ce la fa ad eseguirlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# selected_columns = ['bytes_in', 'bytes_out', 'num_pkts_out', 'num_pkts_in', 'proto', 'time_start']\n",
    "\n",
    "# # Impostazione della griglia di subplot\n",
    "# n_columns = len(selected_columns)\n",
    "# n_rows = (n_columns + 1) // 2  # Organizza i subplot in due colonne\n",
    "\n",
    "# fig, axes = plt.subplots(n_rows, 2, figsize=(12, 5 * n_rows))\n",
    "# axes = axes.flatten()  # Rende l'array bidimensionale unidimensionale per un accesso più semplice\n",
    "\n",
    "# for i, col in enumerate(selected_columns):\n",
    "#     sns.histplot(df[col], kde=True, ax=axes[i])\n",
    "#     axes[i].set_title(f\"Distribution of column {col}\")\n",
    "\n",
    "# # Nascondi eventuali subplot vuoti\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical = df.drop(columns=['label', 'src_ip', 'dest_ip'])\n",
    "correlation_matrix = df_numerical.corr()\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nan = df.isna().sum().sum()\n",
    "print(\"Total NaN values in DataFrame:\", total_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = df[df.isna().any(axis=1)]\n",
    "print(rows_with_nan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
