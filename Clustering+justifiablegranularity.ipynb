{"cells":[{"cell_type":"markdown","id":"2caa1f00","metadata":{"id":"2caa1f00"},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":null,"id":"36751954","metadata":{"id":"36751954"},"outputs":[],"source":["import os\n","import glob\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","id":"zQCuH_8Qx_FK","metadata":{"id":"zQCuH_8Qx_FK"},"source":["# Connection to drive"]},{"cell_type":"code","execution_count":null,"id":"8e541e17","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1727684224260,"user":{"displayName":"DAMIANA IOVARO","userId":"12500258692918933283"},"user_tz":-120},"id":"8e541e17","outputId":"ee9a8e89-2a07-4d2c-a784-9437f929191d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on Google Colab. \n"]}],"source":["try:\n","    from google.colab import drive\n","    IN_COLAB = True\n","    print(\"Running on Google Colab. \")\n","except:\n","    IN_COLAB = False\n","    print(\"Not running on Google Colab. \")"]},{"cell_type":"code","execution_count":null,"id":"YqDnszP3yBxG","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24352,"status":"ok","timestamp":1727684248607,"user":{"displayName":"DAMIANA IOVARO","userId":"12500258692918933283"},"user_tz":-120},"id":"YqDnszP3yBxG","outputId":"d6dadbf6-66a4-4a8c-f156-1e4675382495"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"id":"vKxzLLMyXlXw","metadata":{"id":"vKxzLLMyXlXw"},"outputs":[],"source":["if IN_COLAB:\n","    os.chdir('/content/gdrive/MyDrive/Tesi/dataset')"]},{"cell_type":"markdown","id":"0f55febe","metadata":{"id":"0f55febe"},"source":["# Reading and Merging Data"]},{"cell_type":"code","execution_count":null,"id":"7de302cf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1727684249435,"user":{"displayName":"DAMIANA IOVARO","userId":"12500258692918933283"},"user_tz":-120},"id":"7de302cf","outputId":"de4d0414-aa4c-43c9-bf52-af01eddbb27b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Already extracted\n"]}],"source":["import zipfile\n","\n","extract_dir = \"./LUFlow\"\n","\n","if not os.path.exists(\"./LUFlow\"):\n","\n","    zip_file_path = \"./LUFlow.zip\"\n","\n","    # Open the zip file and extract all the files\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_dir)\n","\n","    print(\"Files extracted successfully.\")\n","else:\n","    print('Already extracted')"]},{"cell_type":"code","execution_count":null,"id":"2dd63090","metadata":{"id":"2dd63090"},"outputs":[],"source":["df_list = []\n","i = 0\n","\n","for root, dirs, files in os.walk(extract_dir):\n","    for file in files:\n","        # checks if 'file' does not exist in the directory\n","        # checks if 'csv' is in the file name\n","        # checks if a particular string is in the file name\n","        # insert in the list only a subset of the existing files\n","        if not os.path.isfile(file) and 'csv' in file and '2020.08' in file and i < 6:\n","            df_list.append(pd.read_csv(os.path.join(root, file)))\n","            i+=1\n","\n","perc = 0.8\n","\n","files_perc = int(len(df_list) * perc)\n","print(f'Num files: {files_perc}')\n","\n","df = pd.concat(df_list[:files_perc])\n","df_test = pd.concat(df_list[files_perc:])\n","\n","df = pd.concat(df_list, ignore_index=True)\n","len(df.columns)"]},{"cell_type":"code","execution_count":null,"id":"957fba95","metadata":{"id":"957fba95"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","id":"81d202a8","metadata":{"id":"81d202a8"},"source":["# Exploratory Data Analysis"]},{"cell_type":"code","execution_count":null,"id":"1424708b","metadata":{"id":"1424708b"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Count the occurrences of each label\n","label_counts = df['label'].value_counts()\n","\n","plt.figure(figsize=(8, 8))\n","plt.pie(label_counts, labels=label_counts.index, autopct=lambda p: '{:.0f}\\n({:.1f}%)'.format(p * sum(label_counts) / 100, p))\n","\n","# Show the plot\n","plt.title('Distribution of Labels')\n","plt.show()"]},{"cell_type":"markdown","id":"e6118ed4","metadata":{"id":"e6118ed4"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"d04422fa","metadata":{"id":"d04422fa"},"outputs":[],"source":["outliers = df['label'] == 'outlier'\n","df = df[~outliers]\n","\n","df = df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"id":"kYo4jc63q_vs","metadata":{"id":"kYo4jc63q_vs"},"outputs":[],"source":["outliers = df_test['label'] == 'outlier'\n","df_test = df_test[~outliers]\n","\n","df_test = df_test.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"id":"66c37230","metadata":{"id":"66c37230"},"outputs":[],"source":["columns_to_drop = ['avg_ipt', 'dest_ip', 'dest_port', 'entropy', 'src_ip', 'src_port', 'time_end', 'total_entropy', 'duration']\n","\n","# Drop specified columns\n","df = df.drop(columns=columns_to_drop)\n","\n","df_test = df_test.drop(columns=columns_to_drop)"]},{"cell_type":"code","execution_count":null,"id":"fe1241d8","metadata":{"id":"fe1241d8"},"outputs":[],"source":["df.dropna(axis=1, inplace = True)\n","df_test.dropna(axis=1, inplace = True)\n","\n","missing_values = df.isnull().sum()\n","\n","print(missing_values)"]},{"cell_type":"code","execution_count":null,"id":"78134a11","metadata":{"id":"78134a11"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the label column\n","df['label'] = label_encoder.fit_transform(df['label'])\n","df_test['label'] = label_encoder.fit_transform(df_test['label'])"]},{"cell_type":"code","execution_count":null,"id":"e945052c","metadata":{"id":"e945052c"},"outputs":[],"source":["# Count the occurrences of each label\n","label_counts = df['label'].value_counts()\n","\n","plt.figure(figsize=(8, 8))\n","plt.pie(label_counts, labels=label_counts.index, autopct=lambda p: '{:.0f}\\n({:.1f}%)'.format(p * sum(label_counts) / 100, p))\n","# Show the plot\n","plt.title('Distribution of Labels')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"_tt-YtWchGYq","metadata":{"id":"_tt-YtWchGYq"},"outputs":[],"source":["df.columns"]},{"cell_type":"markdown","id":"k90MxbIk_G_J","metadata":{"id":"k90MxbIk_G_J"},"source":["## Construction of Interval Information Granules\n","\n","### Selecting index using time windows"]},{"cell_type":"code","execution_count":null,"id":"vyXIigQju030","metadata":{"id":"vyXIigQju030"},"outputs":[],"source":["time_slices = [16, 128, 256, 1024, 2048, 3016]\n","\n","matching_indices_slices = {}\n","\n","for ts in time_slices:\n","  # maximum time limit of the granule\n","  limit = df.iloc[0]['time_start'] + ts\n","  # number of groups for time_slice\n","  num_group = 0\n","  matching_indices_slices[ts] = {num_group:[0]}\n","\n","  for i, row in df.iterrows():\n","      # if the value of time_start is greater than limit then limit is updated and\n","      # it is initilized a new group\n","      # otherwise the index of the row is added to matching_indeces_slices\n","      if row['time_start'] >= limit:\n","        limit = row['time_start'] + ts\n","        num_group += 1\n","\n","        matching_indices_slices[ts][num_group] = [i]\n","      else:\n","        # print(ts, num_gran, i)\n","        if i != 0:\n","          matching_indices_slices[ts][num_group].append(i)\n"]},{"cell_type":"markdown","id":"zZMBBfdMA4NV","metadata":{"id":"zZMBBfdMA4NV"},"source":["### Drop Label column"]},{"cell_type":"code","execution_count":null,"id":"d96cee97","metadata":{"id":"d96cee97"},"outputs":[],"source":["# Separate features (X) and target variable (y)\n","X_train = df.drop('label', axis=1)\n","y_train = df['label']\n","\n","X_test = df_test.drop('label', axis=1)\n","y_test = df_test['label']"]},{"cell_type":"code","execution_count":null,"id":"911c3e12","metadata":{"id":"911c3e12"},"outputs":[],"source":["X_train"]},{"cell_type":"code","execution_count":null,"id":"1de93880","metadata":{"id":"1de93880"},"outputs":[],"source":["y_train"]},{"cell_type":"code","execution_count":null,"id":"2058ae5b","metadata":{"id":"2058ae5b"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm\n","import math"]},{"cell_type":"markdown","source":["### Creating interval information granules\n","\n","with justifiable granularity principle\n"],"metadata":{"id":"t8o0K9k6npXH"},"id":"t8o0K9k6npXH"},{"cell_type":"code","execution_count":null,"id":"_dvzK55YBC1D","metadata":{"id":"_dvzK55YBC1D"},"outputs":[],"source":["X_train_granule = {}\n","y_train_granule = {}\n","\n","experimental_data = {}\n","\n","alpha = 2.0\n","l = 100\n","\n","for time_slice in tqdm(time_slices):\n","  X_train_granule[time_slice] = {}\n","  y_train_granule[time_slice] = {}\n","\n","  experimental_data[time_slice] = {}\n","\n","  for group in matching_indices_slices[time_slice]:\n","\n","    V_b_opt = float('-inf')\n","    # obtains index for previous defined groups\n","    group_indeces = matching_indices_slices[time_slice][group]\n","\n","    experimental_data[time_slice][group] = X_train.iloc[group_indeces]\n","\n","    N = len(experimental_data[time_slice][group])\n","\n","    a = X_train.iloc[group_indeces]['time_start'].head(1)\n","\n","    m = experimental_data[time_slice][group].mean()\n","    y_max = experimental_data[time_slice][group].max()\n","\n","    delta_y = (y_max - m)/l\n","\n","    for h in range(0, l):\n","      b = m['time_start']+h*delta_y['time_start']\n","\n","      cov = len(experimental_data[time_slice][group][(experimental_data[time_slice][group]['time_start'] <= b)])/N  # capire se <= o <\n","\n","      sp = math.exp(-alpha*abs(m['time_start']-b))\n","\n","      V_b = cov*sp\n","\n","      if V_b > V_b_opt:\n","        b_opt = b\n","        V_b_opt = V_b\n","\n","\n","    X_train_granule[time_slice][group] = experimental_data[time_slice][group][(experimental_data[time_slice][group]['time_start'] <= b_opt)] # capire se <= o <\n","    y_train_granule[time_slice][group] = y_train.iloc[X_train_granule[time_slice][group].index]\n"]},{"cell_type":"markdown","source":["### Training of Random Forest models"],"metadata":{"id":"rMYodOgOo0nB"},"id":"rMYodOgOo0nB"},{"cell_type":"code","execution_count":null,"id":"J4Gpy_rikamQ","metadata":{"id":"J4Gpy_rikamQ"},"outputs":[],"source":["from tqdm import tqdm\n","\n","list_reports = {}\n","best_models = {}\n","\n","# Random Forest with GridSearchCV\n","rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n","rf_model = RandomForestClassifier()\n","rf_grid = GridSearchCV(rf_model, rf_params, cv=10, scoring='accuracy')\n","\n","\n","for time_slice in tqdm(time_slices):\n","  y_train_list = pd.concat(y_train_granule[time_slice].values(), ignore_index=True)\n","  X_train_granule_df = pd.concat(X_train_granule[time_slice].values(), ignore_index=True)\n","\n","  list_reports[time_slice] = {}\n","  best_models[time_slice] = {}\n","\n","  rf_grid.fit(X_train_granule_df, y_train_list)\n","  rf_best_model = rf_grid.best_estimator_\n","\n","  rf_pred = rf_best_model.predict(X_test)\n","  report = classification_report(y_test, rf_pred, output_dict=True)\n","\n","  list_reports[time_slice] = pd.DataFrame(report).transpose()\n","  best_models[time_slice] = rf_best_model"]},{"cell_type":"markdown","id":"92521af6","metadata":{"id":"92521af6"},"source":["# Model Performance"]},{"cell_type":"code","execution_count":null,"id":"v000UeVoJMd6","metadata":{"id":"v000UeVoJMd6"},"outputs":[],"source":["import time\n","import joblib\n","\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n","\n","os.mkdir(f'./reports/{timestr}')\n","os.mkdir(f'./best_models/{timestr}')\n","\n","os.chdir(f'./reports/{timestr}')\n","\n","for report in list_reports:\n","  list_reports[report].to_csv(f'report_{report}.csv')\n","\n","\n","os.chdir(f'../../best_models/{timestr}')\n","\n","for model in best_models:\n","  joblib.dump(best_models[model], f'model_{model}_{timestr}.joblib')"]},{"cell_type":"code","execution_count":null,"id":"icbCgYKqIDXX","metadata":{"id":"icbCgYKqIDXX"},"outputs":[],"source":["equidistant_x = np.arange(len(time_slices))\n","feature_to_print = 'precision'\n","\n","plt.plot(equidistant_x, [list_reports[i].loc['accuracy'][feature_to_print] for i in time_slices])\n","\n","plt.title(f'{feature_to_print} over time_slices')\n","plt.xticks(equidistant_x, time_slices)\n","plt.xlabel('time slices')\n","plt.ylabel(f'{feature_to_print}')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"-Jvtsd3wlAOL","metadata":{"id":"-Jvtsd3wlAOL"},"outputs":[],"source":["for time_slice in time_slices:\n","  print(f'Report {time_slice}: \\n{list_reports[time_slice]}')\n","  print('\\n')"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":975848,"sourceId":7295614,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"papermill":{"default_parameters":{},"duration":459.535705,"end_time":"2024-01-02T19:22:34.876445","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-02T19:14:55.340740","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}